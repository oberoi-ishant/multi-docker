# NOTES:
# For Production.
# https://www.udemy.com/course/docker-and-kubernetes-the-complete-guide/learn/lecture/11437358#questions/9889368
# Related to Dockerrun.aws.json file.
# Image to check in folder: amazon-ecs-task-definition
# So you will write a task definition file that will be
# consumed by Amazon ECS. One task definition file has instruction
# for ONLY one container.
# So in Dockerrun.aws.json we write the task definition that is essntially
# used by ECS. Elastic Beanstalk delegated the task to ECS to understand
# mutli container deployment.
# Also in Dockerrun.aws.json there should be atleast one container as
# essential:true in containerDefinitions.
# Essential contianer means that is the most important one. If this
# container crashes, then stop all other containers.
# In out project, if nginx crashes users can not visit the site, so we make it essential: true.
# For Amazon ECS task definition parameters link is
# https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html#container_definitions
# Like in docker-compose file we listed SERVICES by name and used these names
# in code like http://client. We know SERVICES running
# have a network and they can access each other using this name.
# Similary we use the name as hostname key in Dockerrun.aws.json file.
# hostname is optinal field though. Since no other services needs to
# reach out to nginx in the Dockerrun.aws.json file we can omit
# hostname in nginx container definition. No harm if it is there.
# links property in Dockerrun.aws.json. For nginx to know that two such
# CONTAINERS exist we specify link as the "name" property of the container for
# containerMapping. This establishes a link for nginx to route traffice
# between these containers. See image link-prop-dockerrun-aws.png

# In Production, we did not mention anything about postgres and redis services
# that we had in our application like in docker-compose.
# Neither did we create their images on travisci.
# Because we will use Amazon services out of the box of these.
# Check images app-prod-structure-with-aws-services, aws-elastic-cache-for-redis
# aws-elastic-cache-for-redis. We will use these service from aws.
# Will AWS Elastic cache for redis
# AWS Relational Database Service(RDS) for postgres.
# For advantages see the images.


# By default ElasticCache and RDS can't talk to beanstalk so we need to create
# security groups.
# Check images to understand the vpc - virtual private cloud and
# security groups.
# VPC is virtual cloud for every region on amazonaws like us-east-2.
# Every region will have one default vpc. This ensures your containers
# are available only to your account.
# security group describe the firewall rules for these vpc.
# they descibe rules for what different services or sources on internet can connect with
# with what services running inside the vpc.
# security group was create for you when you create the elastic Beanstalk
# instance. Be sure your are in the region where you created the Beanstalk instance.
# In the vpc page on left check security group and you should see One
# with the name related to your beanstalk project.
# check image. You can also see the rule for traffic inbound and outbond rule
# displayed in the image security-group-example and security-group-def

# So we also create one rule in security group saying
# "Allow any traffic coming from any AWS service that has this security group"
# Allow such traffic to pass through and let these services communicate.
# And will attach this securitygroup to our serivces elastic beanstalk, redis(Elastic cache) and
# postgres(AWS RDS). Image: new-security-rule-for-our-aws-services

# Create RDS on aws services
# https://www.udemy.com/course/docker-and-kubernetes-the-complete-guide/learn/lecture/11437376#questions/9889368
# free tier - postgres
# AWS RDS: master username: postgres
# master password: postgrespassword
# DBinstance size: db.t2.micro (the free one by default)
# Virtual Private Cloud: Default-vpc (where ElasticBeanstalk instance created)
# public accessibility: no
# vpc security group: create new for now.
# Databasename: fibvalues
# DB instance identifier: multi-docker-postgres
# vpc security group name: multi-docker-vpcgroup

# Create ElasticCache
# https://www.udemy.com/course/docker-and-kubernetes-the-complete-guide/learn/lecture/11437378#questions/9889368
# AWS- Elastic Cache
# Hit redis on left -> create
# name: multi-docker-redis
# Node type: t2 -> cache.t2.micro (cheapest)
# Subnet group: name: redis-group.
# choose default vpc for vpc id.
# select the Subnet check boxes
# created successfully.

# Security Group Add Rule(firewall rules)
# now select your securitygroup -> inbound rules -> edit -> add rule (Image: security-group-create)
# port range can be zero but we will restrict to our ports of
# postgres(5432) and redis(6379). So type 5432-6379
# security groups: type the group id of the securitygroup just created. eg sg-020c7dcf7e67b3780 you can copy it from the description
# of securitygroup created on the description tag.(previous tab)

# Now apply securitygroup to ElasticCache and RDS and Beanstalk.
# Go to ElasticCache - Redis - select your redis ins - multi-docker-redis
# modify -> select the newly greate securitygroup.
# go to RDS - your db instance multi-docker-postgres
# modify -> select your securitygroup. Save
# go to ElasticBeanstalk -> you instance -> Configuration -> instances
# modify -> select your securitygroup. Apply/Confirm.

# Setting environment vriables for containers running inside ElasticBeanstalk
# to access RDS and ElasticCache.
# ElasticBeanstalk ->configure -> software ->modify
# Environment Properties
# Use image RDS-Env-variable-endpoint-port and REDIS-Env-variable-endpoint-port
# You need to basically get the endpoint and port from your running instances
# of RDS and ElasticCache on the aws.
# And use the postgres variables saved above user name password Database name.
# Will add all the environment variables as specified on docker-compose file
# for the api (server part).
# - REDIS_HOST=endpoint(image)
  - REDIS_PORT=port(image)
  - PGUSER=postgres
  - PGHOST=endpoint(image)
  - PGDATABASE=fibvalues(from above when created)
  - PGPASSWORD=postgrespassword (from above when created)
  - PGPORT=port(image)
# In ElasticBeanstalk when you list environment variables they automatically
# pass down to every container listed in the Dockerrun.aws.json.
# so you dont have to add them in every service like we did in docker-compose
# for api, worker etc.

# IAM
# AWS -> services -> IAM
# new user
# name: multi-docker-deployer
# permission: serach for ElasticBeanstalk and add all
# create user.

# Add deploy steps to travis.yml
# Here ElasticBeanstalk picks all Configuration from the
# Dockerrun.aws.json file.